{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af150e7-bf06-4ea5-9edd-3f3990bcd67d",
   "metadata": {},
   "source": [
    "##### Please do not run the section2 for the hyperparameter tuning, only run the section1 and section3 to import requirments and the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac920027-09c3-43b3-ac4a-4d8a86ce186e",
   "metadata": {},
   "source": [
    "# 1. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1968a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nir/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import anchor_estimator\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper import (\n",
    "    load_dataset,\n",
    "    split_data,\n",
    "    run_single_experiment,\n",
    "    run_all_experiments,\n",
    "    tune_hyperparams\n",
    ")\n",
    "\n",
    "from cnn_model import cnn_model\n",
    "from loss_functions import (\n",
    "    symmetric_cross_entropy,\n",
    "    forward_correction_loss,\n",
    "    CoTeachingProxyLoss,\n",
    "    RememberRateScheduler,\n",
    "    _infer_noise_rate_from_name, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320cd03",
   "metadata": {},
   "source": [
    "# 2. Hyper-parameter tuning code: do not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae20a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning SCE on FashionMNIST0.3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 21:46:45.502965: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-05 21:46:45.502997: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-05 21:46:45.503003: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762339605.503394  316267 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762339605.503442  316267 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-05 21:46:45.960863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Tuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtune_hyperparams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_dev_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# lightweight dev budget\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     tuned[(dataset, method)] \u001b[38;5;241m=\u001b[39m best_params\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/helper.py:106\u001b[0m, in \u001b[0;36mtune_hyperparams\u001b[0;34m(Xtr, Str, dataset, method, input_shape, num_classes, n_dev_runs, epochs)\u001b[0m\n\u001b[1;32m    103\u001b[0m X_tr, y_tr, X_va, y_va \u001b[38;5;241m=\u001b[39m split_data(Xtr, Str, train_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msce\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 106\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43msce_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoteaching\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    113\u001b[0m     model \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m    114\u001b[0m         X_tr, y_tr, X_va, y_va,\n\u001b[1;32m    115\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoteaching\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mepochs, input_shape\u001b[38;5;241m=\u001b[39minput_shape, num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m    117\u001b[0m         coteaching_params\u001b[38;5;241m=\u001b[39mparams\n\u001b[1;32m    118\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/helper.py:192\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_val, y_val, dataset, method, transition_matrix, epochs, input_shape, num_classes, sce_params, coteaching_params, learning_rate)\u001b[0m\n\u001b[1;32m    182\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    183\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m    184\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss_function,\n\u001b[1;32m    185\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    186\u001b[0m )\n\u001b[1;32m    188\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m    189\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m )\n\u001b[0;32m--> 192\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# datasets = ['FashionMNIST0.3', 'FashionMNIST0.6', 'CIFAR']\n",
    "# methods  = ['sce']\n",
    "\n",
    "# # One-time tuning per dataset × method\n",
    "# tuned = {}  # key: (dataset, method) -> param dict\n",
    "# for dataset in datasets:\n",
    "#     data_path = f'datasets/{dataset}.npz'\n",
    "#     Xtr, Str, Xts, Yts, T = load_dataset(data_path, dataset)\n",
    "#     input_shape = Xtr.shape[1:]\n",
    "\n",
    "#     for method in methods:\n",
    "#         print(f\"\\n=== Tuning {method.upper()} on {dataset} ===\")\n",
    "#         best_params = tune_hyperparams(\n",
    "#             Xtr, Str, dataset, method, input_shape,\n",
    "#             n_dev_runs=3, epochs=30  # lightweight dev budget\n",
    "#         )\n",
    "#         tuned[(dataset, method)] = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f11cd-4bd7-48cd-9a72-cabd5565513c",
   "metadata": {},
   "source": [
    "## 2.1 Hyperparams for sce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f5f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('FashionMNIST0.3', 'sce'): {'alpha': 0.01,\n",
       "  'beta': 1.0,\n",
       "  'A': -1.0,\n",
       "  'lr': 0.001},\n",
       " ('FashionMNIST0.6', 'sce'): {'alpha': 0.01,\n",
       "  'beta': 0.5,\n",
       "  'A': -4.0,\n",
       "  'lr': 0.001},\n",
       " ('CIFAR', 'sce'): {'alpha': 0.05, 'beta': 1.0, 'A': -4.0, 'lr': 0.001}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparams for sce\n",
    "tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fc2d8-048d-4cbe-a0c7-90cbc0b25327",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparams for COTEACHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e45ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning COTEACHING on FashionMNIST0.3 ===\n",
      "[TUNE] dataset=FashionMNIST0.3 method=coteaching params={'warmup': 3, 'lr': 0.001} -> val_acc=0.6779\n",
      "[TUNE] dataset=FashionMNIST0.3 method=coteaching params={'warmup': 3, 'lr': 0.0005} -> val_acc=0.6778\n",
      "[TUNE] dataset=FashionMNIST0.3 method=coteaching params={'warmup': 5, 'lr': 0.001} -> val_acc=0.6801\n",
      "[TUNE] dataset=FashionMNIST0.3 method=coteaching params={'warmup': 5, 'lr': 0.0005} -> val_acc=0.6784\n",
      "[TUNE] dataset=FashionMNIST0.3 method=coteaching params={'warmup': 10, 'lr': 0.001} -> val_acc=0.6811\n",
      "[TUNE] dataset=FashionMNIST0.3 method=coteaching params={'warmup': 10, 'lr': 0.0005} -> val_acc=0.6756\n",
      "[TUNE][BEST] dataset=FashionMNIST0.3 method=coteaching -> {'warmup': 10, 'lr': 0.001} (val_acc=0.6811)\n",
      "\n",
      "=== Tuning COTEACHING on FashionMNIST0.6 ===\n",
      "[TUNE] dataset=FashionMNIST0.6 method=coteaching params={'warmup': 3, 'lr': 0.001} -> val_acc=0.3821\n",
      "[TUNE] dataset=FashionMNIST0.6 method=coteaching params={'warmup': 3, 'lr': 0.0005} -> val_acc=0.3885\n",
      "[TUNE] dataset=FashionMNIST0.6 method=coteaching params={'warmup': 5, 'lr': 0.001} -> val_acc=0.3852\n",
      "[TUNE] dataset=FashionMNIST0.6 method=coteaching params={'warmup': 5, 'lr': 0.0005} -> val_acc=0.3917\n",
      "[TUNE] dataset=FashionMNIST0.6 method=coteaching params={'warmup': 10, 'lr': 0.001} -> val_acc=0.3808\n",
      "[TUNE] dataset=FashionMNIST0.6 method=coteaching params={'warmup': 10, 'lr': 0.0005} -> val_acc=0.3849\n",
      "[TUNE][BEST] dataset=FashionMNIST0.6 method=coteaching -> {'warmup': 5, 'lr': 0.0005} (val_acc=0.3917)\n",
      "\n",
      "=== Tuning COTEACHING on CIFAR ===\n",
      "[TUNE] dataset=CIFAR method=coteaching params={'warmup': 3, 'lr': 0.001} -> val_acc=0.3688\n",
      "[TUNE] dataset=CIFAR method=coteaching params={'warmup': 3, 'lr': 0.0005} -> val_acc=0.3628\n",
      "[TUNE] dataset=CIFAR method=coteaching params={'warmup': 5, 'lr': 0.001} -> val_acc=0.3483\n",
      "[TUNE] dataset=CIFAR method=coteaching params={'warmup': 5, 'lr': 0.0005} -> val_acc=0.3767\n",
      "[TUNE] dataset=CIFAR method=coteaching params={'warmup': 10, 'lr': 0.001} -> val_acc=0.3543\n",
      "[TUNE] dataset=CIFAR method=coteaching params={'warmup': 10, 'lr': 0.0005} -> val_acc=0.3627\n",
      "[TUNE][BEST] dataset=CIFAR method=coteaching -> {'warmup': 5, 'lr': 0.0005} (val_acc=0.3767)\n"
     ]
    }
   ],
   "source": [
    "# datasets = ['FashionMNIST0.3', 'FashionMNIST0.6', 'CIFAR']\n",
    "# methods  = ['coteaching']\n",
    "\n",
    "# # One-time tuning per dataset × method\n",
    "# tuned_coteaching = {}  # key: (dataset, method) -> param dict\n",
    "# for dataset in datasets:\n",
    "#     data_path = f'datasets/{dataset}.npz'\n",
    "#     Xtr, Str, Xts, Yts, T = load_dataset(data_path, dataset)\n",
    "#     input_shape = Xtr.shape[1:]\n",
    "\n",
    "#     for method in methods:\n",
    "#         print(f\"\\n=== Tuning {method.upper()} on {dataset} ===\")\n",
    "#         best_params = tune_hyperparams(\n",
    "#             Xtr, Str, dataset, method, input_shape,\n",
    "#             n_dev_runs=3, epochs=30  # lightweight dev budget\n",
    "#         )\n",
    "#         tuned_coteaching[(dataset, method)] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b91127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('FashionMNIST0.3', 'coteaching'): {'warmup': 10, 'lr': 0.001},\n",
       " ('FashionMNIST0.6', 'coteaching'): {'warmup': 5, 'lr': 0.0005},\n",
       " ('CIFAR', 'coteaching'): {'warmup': 5, 'lr': 0.0005}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_coteaching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2aa1d7",
   "metadata": {},
   "source": [
    "# 3. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139873c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BASELINE on FashionMNIST0.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 13:46:44.735144: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-06 13:46:44.735180: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-06 13:46:44.735187: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762397204.735226   45579 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762397204.735269   45579 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-06 13:46:45.105909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10: Test Accuracy = 93.03%\n",
      "Run 2/10: Test Accuracy = 94.93%\n",
      "Run 3/10: Test Accuracy = 91.27%\n",
      "Run 4/10: Test Accuracy = 97.80%\n",
      "Run 5/10: Test Accuracy = 94.33%\n",
      "Run 6/10: Test Accuracy = 92.40%\n",
      "Run 7/10: Test Accuracy = 92.93%\n",
      "Run 8/10: Test Accuracy = 95.13%\n",
      "Run 9/10: Test Accuracy = 95.77%\n",
      "Run 10/10: Test Accuracy = 91.03%\n",
      "Result: 93.86 ± 2.01%\n",
      "Running FORWARD on FashionMNIST0.3...\n",
      "Run 1/10: Test Accuracy = 98.97%\n",
      "Run 2/10: Test Accuracy = 99.10%\n",
      "Run 3/10: Test Accuracy = 98.83%\n",
      "Run 4/10: Test Accuracy = 99.17%\n",
      "Run 5/10: Test Accuracy = 99.23%\n",
      "Run 6/10: Test Accuracy = 99.00%\n",
      "Run 7/10: Test Accuracy = 98.90%\n",
      "Run 8/10: Test Accuracy = 99.17%\n",
      "Run 9/10: Test Accuracy = 99.13%\n",
      "Run 10/10: Test Accuracy = 99.20%\n",
      "Result: 99.07 ± 0.13%\n",
      "Running SCE on FashionMNIST0.3...\n",
      "Run 1/10: Test Accuracy = 98.63%\n",
      "Run 2/10: Test Accuracy = 97.53%\n",
      "Run 3/10: Test Accuracy = 98.43%\n",
      "Run 4/10: Test Accuracy = 98.30%\n",
      "Run 5/10: Test Accuracy = 98.57%\n",
      "Run 6/10: Test Accuracy = 98.80%\n",
      "Run 7/10: Test Accuracy = 98.43%\n",
      "Run 8/10: Test Accuracy = 96.10%\n",
      "Run 9/10: Test Accuracy = 98.73%\n",
      "Run 10/10: Test Accuracy = 98.33%\n",
      "Result: 98.19 ± 0.77%\n",
      "Running COTEACHING on FashionMNIST0.3...\n",
      "Run 1/10: Test Accuracy = 98.63%\n",
      "Run 2/10: Test Accuracy = 97.07%\n",
      "Run 3/10: Test Accuracy = 98.57%\n",
      "Run 4/10: Test Accuracy = 93.43%\n",
      "Run 5/10: Test Accuracy = 98.27%\n",
      "Run 6/10: Test Accuracy = 98.67%\n",
      "Run 7/10: Test Accuracy = 95.17%\n",
      "Run 8/10: Test Accuracy = 98.50%\n",
      "Run 9/10: Test Accuracy = 98.67%\n",
      "Run 10/10: Test Accuracy = 98.27%\n",
      "Result: 97.52 ± 1.72%\n",
      "Running BASELINE on FashionMNIST0.6...\n",
      "Run 1/10: Test Accuracy = 95.80%\n",
      "Run 2/10: Test Accuracy = 96.00%\n",
      "Run 3/10: Test Accuracy = 94.53%\n",
      "Run 4/10: Test Accuracy = 94.37%\n",
      "Run 5/10: Test Accuracy = 95.97%\n",
      "Run 6/10: Test Accuracy = 95.17%\n",
      "Run 7/10: Test Accuracy = 95.23%\n",
      "Run 8/10: Test Accuracy = 95.03%\n",
      "Run 9/10: Test Accuracy = 93.30%\n",
      "Run 10/10: Test Accuracy = 93.27%\n",
      "Result: 94.87 ± 0.95%\n",
      "Running FORWARD on FashionMNIST0.6...\n",
      "Run 1/10: Test Accuracy = 93.93%\n",
      "Run 2/10: Test Accuracy = 94.37%\n",
      "Run 3/10: Test Accuracy = 96.27%\n",
      "Run 4/10: Test Accuracy = 94.80%\n",
      "Run 5/10: Test Accuracy = 95.07%\n",
      "Run 6/10: Test Accuracy = 95.00%\n",
      "Run 7/10: Test Accuracy = 95.87%\n",
      "Run 8/10: Test Accuracy = 93.83%\n",
      "Run 9/10: Test Accuracy = 94.27%\n",
      "Run 10/10: Test Accuracy = 62.47%\n",
      "Result: 91.59 ± 9.74%\n",
      "Running SCE on FashionMNIST0.6...\n",
      "Run 1/10: Test Accuracy = 95.07%\n",
      "Run 2/10: Test Accuracy = 95.43%\n",
      "Run 3/10: Test Accuracy = 94.67%\n",
      "Run 4/10: Test Accuracy = 96.17%\n",
      "Run 5/10: Test Accuracy = 94.70%\n",
      "Run 6/10: Test Accuracy = 95.27%\n",
      "Run 7/10: Test Accuracy = 95.57%\n",
      "Run 8/10: Test Accuracy = 96.67%\n",
      "Run 9/10: Test Accuracy = 95.60%\n",
      "Run 10/10: Test Accuracy = 95.97%\n",
      "Result: 95.51 ± 0.60%\n",
      "Running COTEACHING on FashionMNIST0.6...\n",
      "Run 1/10: Test Accuracy = 94.47%\n",
      "Run 2/10: Test Accuracy = 85.93%\n",
      "Run 3/10: Test Accuracy = 90.07%\n",
      "Run 4/10: Test Accuracy = 92.60%\n",
      "Run 5/10: Test Accuracy = 88.30%\n",
      "Run 6/10: Test Accuracy = 88.67%\n",
      "Run 7/10: Test Accuracy = 86.57%\n",
      "Run 8/10: Test Accuracy = 92.90%\n",
      "Run 9/10: Test Accuracy = 94.20%\n",
      "Run 10/10: Test Accuracy = 95.67%\n",
      "Result: 90.94 ± 3.30%\n",
      "Running BASELINE on CIFAR...\n",
      "Run 1/10: Test Accuracy = 57.73%\n",
      "Run 2/10: Test Accuracy = 57.30%\n",
      "Run 3/10: Test Accuracy = 64.13%\n",
      "Run 4/10: Test Accuracy = 63.83%\n",
      "Run 5/10: Test Accuracy = 62.23%\n",
      "Run 6/10: Test Accuracy = 58.30%\n",
      "Run 7/10: Test Accuracy = 63.40%\n",
      "Run 8/10: Test Accuracy = 60.37%\n",
      "Run 9/10: Test Accuracy = 56.50%\n",
      "Run 10/10: Test Accuracy = 68.13%\n",
      "Result: 61.19 ± 3.58%\n",
      "Running FORWARD on CIFAR...\n",
      "Run 1/10: Test Accuracy = 66.57%\n",
      "Run 2/10: Test Accuracy = 69.10%\n",
      "Run 3/10: Test Accuracy = 72.63%\n",
      "Run 4/10: Test Accuracy = 70.97%\n",
      "Run 5/10: Test Accuracy = 66.77%\n",
      "Run 6/10: Test Accuracy = 68.13%\n",
      "Run 7/10: Test Accuracy = 67.80%\n",
      "Run 8/10: Test Accuracy = 70.77%\n",
      "Run 9/10: Test Accuracy = 66.37%\n",
      "Run 10/10: Test Accuracy = 67.53%\n",
      "Result: 68.66 ± 2.03%\n",
      "Running SCE on CIFAR...\n",
      "Run 1/10: Test Accuracy = 62.33%\n",
      "Run 2/10: Test Accuracy = 66.00%\n",
      "Run 3/10: Test Accuracy = 62.40%\n",
      "Run 4/10: Test Accuracy = 61.63%\n",
      "Run 5/10: Test Accuracy = 66.33%\n",
      "Run 6/10: Test Accuracy = 66.97%\n",
      "Run 7/10: Test Accuracy = 63.00%\n",
      "Run 8/10: Test Accuracy = 69.17%\n",
      "Run 9/10: Test Accuracy = 64.90%\n",
      "Run 10/10: Test Accuracy = 61.17%\n",
      "Result: 64.39 ± 2.53%\n",
      "Running COTEACHING on CIFAR...\n",
      "Run 1/10: Test Accuracy = 45.23%\n",
      "Run 2/10: Test Accuracy = 61.73%\n",
      "Run 3/10: Test Accuracy = 58.50%\n",
      "Run 4/10: Test Accuracy = 55.37%\n",
      "Run 5/10: Test Accuracy = 64.33%\n",
      "Run 6/10: Test Accuracy = 63.53%\n",
      "Run 7/10: Test Accuracy = 68.97%\n",
      "Run 8/10: Test Accuracy = 65.03%\n",
      "Run 9/10: Test Accuracy = 58.77%\n",
      "Run 10/10: Test Accuracy = 54.13%\n",
      "Result: 59.56 ± 6.45%\n"
     ]
    }
   ],
   "source": [
    "datasets = ['FashionMNIST0.3', 'FashionMNIST0.6', 'CIFAR']\n",
    "methods = ['baseline','forward', 'sce', 'coteaching'] \n",
    "\n",
    "result = run_all_experiments(datasets, methods, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7815a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10dab4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method               BASELINE    COTEACHING       FORWARD           SCE\n",
      "Dataset                                                                \n",
      "CIFAR            61.19 ± 3.58  59.56 ± 6.45  68.66 ± 2.03  64.39 ± 2.53\n",
      "FashionMNIST0.3  93.86 ± 2.01  97.52 ± 1.72  99.07 ± 0.13  98.19 ± 0.77\n",
      "FashionMNIST0.6  94.87 ± 0.95  90.94 ± 3.30  91.59 ± 9.74  95.51 ± 0.60\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv('result.csv')\n",
    "pivot_df = result.pivot(index='Dataset', columns='Method', values='Result')\n",
    "    \n",
    "print(pivot_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
