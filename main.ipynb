{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1968a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nir/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper import (\n",
    "    load_dataset,\n",
    "    split_data,\n",
    "    run_single_experiment,\n",
    "    run_all_experiments,\n",
    "    tune_hyperparams\n",
    ")\n",
    "\n",
    "from cnn_model import cnn_model\n",
    "from loss_functions import (\n",
    "    symmetric_cross_entropy,\n",
    "    forward_correction_loss,\n",
    "    CoTeachingProxyLoss,\n",
    "    RememberRateScheduler,\n",
    "    _infer_noise_rate_from_name, \n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor_estimator and flc (still wait for check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3588eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:49:04.844746: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-04 13:49:04.844785: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-04 13:49:04.844791: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762224544.844826 15808406 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762224544.844868 15808406 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:49:05.827795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.3324 - loss: 10.7983 - val_accuracy: 0.3370 - val_loss: 10.7187\n",
      "Epoch 2/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3377 - loss: 10.7017 - val_accuracy: 0.3483 - val_loss: 10.5849\n",
      "Epoch 3/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3427 - loss: 10.5812 - val_accuracy: 0.3547 - val_loss: 10.5176\n",
      "Epoch 4/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3470 - loss: 10.6110 - val_accuracy: 0.3557 - val_loss: 10.4575\n",
      "Epoch 5/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3584 - loss: 10.4031 - val_accuracy: 0.3533 - val_loss: 10.4823\n",
      "T_hat col-sums: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# anchor_estimator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from helper import load_dataset, split_data\n",
    "from cnn_model import cnn_model\n",
    "from anchor_estimator import temperature_scale_probs, estimate_T_anchor_from_probs\n",
    "from loss_functions import symmetric_cross_entropy\n",
    "from flc_loss import forward_correction_loss\n",
    "\n",
    "\n",
    "def ensure_column_stochastic(T: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    T = np.clip(T, 0, None)\n",
    "    colsum = T.sum(axis=0, keepdims=True) + eps\n",
    "    return T / colsum\n",
    "\n",
    "\n",
    "Xtr, Str, Xts, Yts, T_true = load_dataset(\"./datasets/CIFAR.npz\", \"CIFAR.npz\")\n",
    "\n",
    "# just avoid the loss from mismatch of onehot/float \n",
    "Str = Str.astype(\"int64\")\n",
    "Yts = Yts.astype(\"int64\")\n",
    "\n",
    "Xtr = Xtr.astype(\"float32\") / 255.0\n",
    "Xts = Xts.astype(\"float32\") / 255.0\n",
    "\n",
    "X_tr, y_tr, X_val, y_val = split_data(Xtr, Str, train_ratio=0.8, random_seed=7)\n",
    "\n",
    "num_classes = int(np.max(Str)) + 1\n",
    "input_shape = Xtr.shape[1:]\n",
    "\n",
    "# 2. Warm-up process, after estimation, the CIFAR.npz is almost same noise 0.6\n",
    "alpha, beta, A = 0.05, 4.0, -4.0   \n",
    "sce_loss = symmetric_cross_entropy(alpha=alpha, beta=beta, A=A, num_classes=num_classes)\n",
    "\n",
    "m = cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "m.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "          loss=sce_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "m.fit(X_tr, y_tr,\n",
    "      validation_data=(X_val, y_val),\n",
    "      epochs=5, batch_size=128, verbose=1)\n",
    "\n",
    "# 3. use the val datasets to get the matrix\n",
    "p_val = m.predict(X_val, batch_size=512, verbose=0)              \n",
    "p_val_cal, bestT = temperature_scale_probs(p_val, y_val)          \n",
    "T_hat = estimate_T_anchor_from_probs(p_val_cal, top_quantile=0.99)  \n",
    "T_hat = ensure_column_stochastic(T_hat).astype(np.float32)\n",
    "\n",
    "print(\"T_hat col-sums:\", T_hat.sum(axis=0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e683acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.3565 - loss: 1.1619 - val_accuracy: 0.3483 - val_loss: 1.0968\n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3453 - loss: 1.0975 - val_accuracy: 0.3607 - val_loss: 1.0950\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3714 - loss: 1.0937 - val_accuracy: 0.3607 - val_loss: 1.0945\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3754 - loss: 1.0934 - val_accuracy: 0.3633 - val_loss: 1.0933\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.3817 - loss: 1.0921 - val_accuracy: 0.3627 - val_loss: 1.0939\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3723 - loss: 1.0925 - val_accuracy: 0.3550 - val_loss: 1.0947\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3746 - loss: 1.0926 - val_accuracy: 0.3597 - val_loss: 1.0920\n",
      "Epoch 8/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3780 - loss: 1.0904 - val_accuracy: 0.3490 - val_loss: 1.0946\n",
      "Epoch 9/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3880 - loss: 1.0897 - val_accuracy: 0.3570 - val_loss: 1.0955\n",
      "Epoch 10/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3875 - loss: 1.0872 - val_accuracy: 0.3540 - val_loss: 1.0933\n",
      "[FLC] Test Accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "# Forward Correction fine-tuning\n",
    "flc_loss = forward_correction_loss(T_hat, num_classes=num_classes)\n",
    "m_flc = cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "m_flc.set_weights(m.get_weights())\n",
    "m_flc.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=flc_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "history_flc = m_flc.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_acc = m_flc.evaluate(Xts, Yts, verbose=0)\n",
    "print(f\"[FLC] Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae20a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning SCE on FashionMNIST0.3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 18:26:54.228285: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-04 18:26:54.228309: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-04 18:26:54.228313: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762241214.228328 16171413 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762241214.228351 16171413 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-04 18:26:54.594201: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.6811\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.6807\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.6808\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.6819\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.6805\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.6738\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.6776\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.6806\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.6819\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.6801\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.6806\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.6816\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.6788\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.6783\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.6792\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.6784\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.6808\n",
      "[TUNE] dataset=FashionMNIST0.3 method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.6800\n",
      "[TUNE][BEST] dataset=FashionMNIST0.3 method=sce -> {'alpha': 0.01, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} (val_acc=0.6819)\n",
      "\n",
      "=== Tuning SCE on FashionMNIST0.6 ===\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3919\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3931\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3937\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3919\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3929\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3931\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3918\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3927\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3930\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3906\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3927\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3933\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3923\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3931\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3914\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3931\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3918\n",
      "[TUNE] dataset=FashionMNIST0.6 method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3928\n",
      "[TUNE][BEST] dataset=FashionMNIST0.6 method=sce -> {'alpha': 0.01, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} (val_acc=0.3937)\n",
      "\n",
      "=== Tuning SCE on CIFAR ===\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3814\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3840\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.01, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3804\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3780\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3852\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.01, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3850\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3770\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3768\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.05, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3848\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3818\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3829\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.05, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3857\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3749\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3801\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.1, 'beta': 0.5, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3800\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -1.0, 'lr': 0.001} -> val_acc=0.3818\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -2.0, 'lr': 0.001} -> val_acc=0.3842\n",
      "[TUNE] dataset=CIFAR method=sce params={'alpha': 0.1, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} -> val_acc=0.3837\n",
      "[TUNE][BEST] dataset=CIFAR method=sce -> {'alpha': 0.05, 'beta': 1.0, 'A': -4.0, 'lr': 0.001} (val_acc=0.3857)\n"
     ]
    }
   ],
   "source": [
    "datasets = ['FashionMNIST0.3', 'FashionMNIST0.6', 'CIFAR']\n",
    "methods  = ['sce']\n",
    "\n",
    "# One-time tuning per dataset × method\n",
    "tuned = {}  # key: (dataset, method) -> param dict\n",
    "for dataset in datasets:\n",
    "    data_path = f'datasets/{dataset}.npz'\n",
    "    Xtr, Str, Xts, Yts, T = load_dataset(data_path, dataset)\n",
    "    input_shape = Xtr.shape[1:]\n",
    "\n",
    "    for method in methods:\n",
    "        print(f\"\\n=== Tuning {method.upper()} on {dataset} ===\")\n",
    "        best_params = tune_hyperparams(\n",
    "            Xtr, Str, dataset, method, input_shape,\n",
    "            n_dev_runs=3, epochs=30  # lightweight dev budget\n",
    "        )\n",
    "        tuned[(dataset, method)] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628f5f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('FashionMNIST0.3', 'sce'): {'alpha': 0.01,\n",
       "  'beta': 1.0,\n",
       "  'A': -1.0,\n",
       "  'lr': 0.001},\n",
       " ('FashionMNIST0.6', 'sce'): {'alpha': 0.01,\n",
       "  'beta': 0.5,\n",
       "  'A': -4.0,\n",
       "  'lr': 0.001},\n",
       " ('CIFAR', 'sce'): {'alpha': 0.05, 'beta': 1.0, 'A': -4.0, 'lr': 0.001}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c682d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running COTEACHING on FashionMNIST0.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 14:21:45.040511: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-04 14:21:45.040543: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-04 14:21:45.040548: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762226505.040563 15883597 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762226505.040585 15883597 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-04 14:21:45.425595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10: Test Accuracy = 94.13%\n",
      "Run 2/10: Test Accuracy = 95.37%\n",
      "Run 3/10: Test Accuracy = 96.80%\n",
      "Run 4/10: Test Accuracy = 94.33%\n",
      "Run 5/10: Test Accuracy = 94.10%\n",
      "Run 6/10: Test Accuracy = 96.27%\n",
      "Run 7/10: Test Accuracy = 92.80%\n",
      "Run 8/10: Test Accuracy = 97.37%\n",
      "Run 9/10: Test Accuracy = 94.80%\n",
      "Run 10/10: Test Accuracy = 95.87%\n",
      "Result: 95.18 ± 1.34%\n",
      "Running COTEACHING on FashionMNIST0.6...\n",
      "Run 1/10: Test Accuracy = 95.50%\n",
      "Run 2/10: Test Accuracy = 92.43%\n",
      "Run 3/10: Test Accuracy = 95.23%\n",
      "Run 4/10: Test Accuracy = 89.90%\n",
      "Run 5/10: Test Accuracy = 92.63%\n",
      "Run 6/10: Test Accuracy = 94.80%\n",
      "Run 7/10: Test Accuracy = 92.87%\n",
      "Run 8/10: Test Accuracy = 94.33%\n",
      "Run 9/10: Test Accuracy = 94.50%\n",
      "Run 10/10: Test Accuracy = 96.50%\n",
      "Result: 93.87 ± 1.82%\n",
      "Running COTEACHING on CIFAR...\n",
      "Run 1/10: Test Accuracy = 63.30%\n",
      "Run 2/10: Test Accuracy = 63.87%\n",
      "Run 3/10: Test Accuracy = 58.07%\n",
      "Run 4/10: Test Accuracy = 61.03%\n",
      "Run 5/10: Test Accuracy = 63.33%\n",
      "Run 6/10: Test Accuracy = 58.83%\n",
      "Run 7/10: Test Accuracy = 60.43%\n",
      "Run 8/10: Test Accuracy = 60.43%\n",
      "Run 9/10: Test Accuracy = 56.87%\n",
      "Run 10/10: Test Accuracy = 66.30%\n",
      "Result: 61.25 ± 2.78%\n"
     ]
    }
   ],
   "source": [
    "datasets = ['FashionMNIST0.3', 'FashionMNIST0.6', 'CIFAR']\n",
    "methods = ['coteaching'] #add more methods here\n",
    "\n",
    "result = run_all_experiments(datasets, methods, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6574152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                    SCE\n",
      "Dataset                      \n",
      "CIFAR            65.57 ± 3.22\n",
      "FashionMNIST0.3  98.58 ± 0.16\n",
      "FashionMNIST0.6  95.83 ± 0.63\n"
     ]
    }
   ],
   "source": [
    "pivot_df = result.pivot(index='Dataset', columns='Method', values='Result')\n",
    "    \n",
    "print(pivot_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
