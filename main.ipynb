{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1968a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nir/Documents/aml/aml-tm/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helper\n",
    "\n",
    "from cnn_model import cnn_model\n",
    "from loss_functions import (\n",
    "    symmetric_cross_entropy,\n",
    "    forward_correction_loss,\n",
    "    CoTeachingProxyLoss,\n",
    "    RememberRateScheduler,\n",
    "    _infer_noise_rate_from_name, \n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor_estimator and flc (still wait for check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3588eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:49:04.844746: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-04 13:49:04.844785: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-04 13:49:04.844791: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762224544.844826 15808406 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762224544.844868 15808406 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:49:05.827795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.3324 - loss: 10.7983 - val_accuracy: 0.3370 - val_loss: 10.7187\n",
      "Epoch 2/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3377 - loss: 10.7017 - val_accuracy: 0.3483 - val_loss: 10.5849\n",
      "Epoch 3/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3427 - loss: 10.5812 - val_accuracy: 0.3547 - val_loss: 10.5176\n",
      "Epoch 4/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3470 - loss: 10.6110 - val_accuracy: 0.3557 - val_loss: 10.4575\n",
      "Epoch 5/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3584 - loss: 10.4031 - val_accuracy: 0.3533 - val_loss: 10.4823\n",
      "T_hat col-sums: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# anchor_estimator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from helper import load_dataset, split_data\n",
    "from cnn_model import cnn_model\n",
    "from anchor_estimator import temperature_scale_probs, estimate_T_anchor_from_probs\n",
    "from loss_functions import symmetric_cross_entropy\n",
    "from flc_loss import forward_correction_loss\n",
    "\n",
    "\n",
    "def ensure_column_stochastic(T: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    T = np.clip(T, 0, None)\n",
    "    colsum = T.sum(axis=0, keepdims=True) + eps\n",
    "    return T / colsum\n",
    "\n",
    "\n",
    "Xtr, Str, Xts, Yts, T_true = load_dataset(\"./datasets/CIFAR.npz\", \"CIFAR.npz\")\n",
    "\n",
    "# just avoid the loss from mismatch of onehot/float \n",
    "Str = Str.astype(\"int64\")\n",
    "Yts = Yts.astype(\"int64\")\n",
    "\n",
    "Xtr = Xtr.astype(\"float32\") / 255.0\n",
    "Xts = Xts.astype(\"float32\") / 255.0\n",
    "\n",
    "X_tr, y_tr, X_val, y_val = split_data(Xtr, Str, train_ratio=0.8, random_seed=7)\n",
    "\n",
    "num_classes = int(np.max(Str)) + 1\n",
    "input_shape = Xtr.shape[1:]\n",
    "\n",
    "# 2. Warm-up process, after estimation, the CIFAR.npz is almost same noise 0.6\n",
    "alpha, beta, A = 0.05, 4.0, -4.0   \n",
    "sce_loss = symmetric_cross_entropy(alpha=alpha, beta=beta, A=A, num_classes=num_classes)\n",
    "\n",
    "m = cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "m.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "          loss=sce_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "m.fit(X_tr, y_tr,\n",
    "      validation_data=(X_val, y_val),\n",
    "      epochs=5, batch_size=128, verbose=1)\n",
    "\n",
    "# 3. use the val datasets to get the matrix\n",
    "p_val = m.predict(X_val, batch_size=512, verbose=0)              \n",
    "p_val_cal, bestT = temperature_scale_probs(p_val, y_val)          \n",
    "T_hat = estimate_T_anchor_from_probs(p_val_cal, top_quantile=0.99)  \n",
    "T_hat = ensure_column_stochastic(T_hat).astype(np.float32)\n",
    "\n",
    "print(\"T_hat col-sums:\", T_hat.sum(axis=0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e683acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.3565 - loss: 1.1619 - val_accuracy: 0.3483 - val_loss: 1.0968\n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3453 - loss: 1.0975 - val_accuracy: 0.3607 - val_loss: 1.0950\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3714 - loss: 1.0937 - val_accuracy: 0.3607 - val_loss: 1.0945\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3754 - loss: 1.0934 - val_accuracy: 0.3633 - val_loss: 1.0933\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.3817 - loss: 1.0921 - val_accuracy: 0.3627 - val_loss: 1.0939\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3723 - loss: 1.0925 - val_accuracy: 0.3550 - val_loss: 1.0947\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3746 - loss: 1.0926 - val_accuracy: 0.3597 - val_loss: 1.0920\n",
      "Epoch 8/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3780 - loss: 1.0904 - val_accuracy: 0.3490 - val_loss: 1.0946\n",
      "Epoch 9/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3880 - loss: 1.0897 - val_accuracy: 0.3570 - val_loss: 1.0955\n",
      "Epoch 10/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3875 - loss: 1.0872 - val_accuracy: 0.3540 - val_loss: 1.0933\n",
      "[FLC] Test Accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "# Forward Correction fine-tuning\n",
    "flc_loss = forward_correction_loss(T_hat, num_classes=num_classes)\n",
    "m_flc = cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "m_flc.set_weights(m.get_weights())\n",
    "m_flc.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=flc_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "history_flc = m_flc.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_acc = m_flc.evaluate(Xts, Yts, verbose=0)\n",
    "print(f\"[FLC] Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debf9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, dataset, method=\"fc\", transition_matrix=None, epochs=50, input_shape=(28, 28, 1), num_classes=3):\n",
    "    \n",
    "    model = cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "    callbacks = []\n",
    "    \n",
    "    if method == \"sce\":\n",
    "        if dataset == \"FashionMNIST0.3\":\n",
    "            alpha = 0.01\n",
    "            beta = 1\n",
    "        elif dataset == \"FashionMNIST0.6\":\n",
    "            alpha = 0.01\n",
    "            beta = 1\n",
    "        elif dataset == \"CIFAR\":\n",
    "            alpha = 0.1\n",
    "            beta = 1\n",
    "        A=-4.0\n",
    "        loss_function = symmetric_cross_entropy(alpha=alpha, beta=beta, A=A, num_classes=num_classes)\n",
    "    # elif method == \"forward\":\n",
    "        #forward function\n",
    "    elif method == \"coteaching\":\n",
    "        # Start with rr=1.0; scheduler will anneal to 1 - noise_rate\n",
    "        loss_obj = CoTeachingProxyLoss(remember_rate=1.0, num_classes=num_classes)\n",
    "        loss_function = loss_obj\n",
    "\n",
    "        noise_rate = _infer_noise_rate_from_name(dataset)\n",
    "        rr_sched = RememberRateScheduler(loss_obj, max_epochs=epochs, noise_rate=noise_rate, warmup=5)\n",
    "        callbacks.append(rr_sched)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss = loss_function,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=128,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predicted_classes == y_test) * 100\n",
    "    return accuracy\n",
    "\n",
    "def run_single_experiment(Xtr, Str, Xts, Yts, T, dataset, method, num_runs=10, epochs=50):\n",
    "    Xtr = Xtr.astype('float32') / 255.0\n",
    "    Xts = Xts.astype('float32') / 255.0\n",
    "    input_shape = Xtr.shape[1:] \n",
    "    \n",
    "    if method == 'fc':\n",
    "        if T is not None:\n",
    "            transition_matrix = T\n",
    "        else:\n",
    "            #call estimate T function here\n",
    "            pass\n",
    "    else:\n",
    "        transition_matrix=None\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        seed = RANDOM_SEED + run\n",
    "\n",
    "        X_train, y_train, X_val, y_val = helper.split_data(\n",
    "            Xtr, Str, train_ratio=0.8, random_seed=seed\n",
    "        )\n",
    "\n",
    "        model = train_model(X_train, y_train, X_val, y_val, dataset=dataset, method=method, transition_matrix=transition_matrix, epochs=epochs, input_shape=input_shape, num_classes=3)\n",
    "\n",
    "        accuracy = evaluate_model(model, Xts, Yts)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Run {run+1}/{num_runs}: Test Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    return accuracies\n",
    "    \n",
    "def run_all_experiments(datasets, methods, num_runs=10, epochs=50):\n",
    "    results = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for method in methods:\n",
    "            print(f\"Running {method.upper()} on {dataset}...\")\n",
    "\n",
    "            data_path = f'datasets/{dataset}.npz'\n",
    "\n",
    "            Xtr, Str, Xts, Yts, T = helper.load_dataset(data_path, dataset) \n",
    "            accuracies = run_single_experiment(\n",
    "                Xtr, Str, Xts, Yts, T, dataset, method, num_runs, epochs\n",
    "            )\n",
    "            mean_acc = np.mean(accuracies)\n",
    "            std_acc = np.std(accuracies)\n",
    "\n",
    "            results.append({\n",
    "                'Dataset': dataset,\n",
    "                'Method': method.upper(),\n",
    "                'Mean': mean_acc,\n",
    "                'Std': std_acc,\n",
    "                'Result': f\"{mean_acc:.2f} ± {std_acc:.2f}\"\n",
    "            })\n",
    "\n",
    "            print(f\"Result: {mean_acc:.2f} ± {std_acc:.2f}%\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c682d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running COTEACHING on FashionMNIST0.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 14:21:45.040511: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-11-04 14:21:45.040543: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-04 14:21:45.040548: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762226505.040563 15883597 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762226505.040585 15883597 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-04 14:21:45.425595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10: Test Accuracy = 94.13%\n",
      "Run 2/10: Test Accuracy = 95.37%\n",
      "Run 3/10: Test Accuracy = 96.80%\n",
      "Run 4/10: Test Accuracy = 94.33%\n",
      "Run 5/10: Test Accuracy = 94.10%\n",
      "Run 6/10: Test Accuracy = 96.27%\n",
      "Run 7/10: Test Accuracy = 92.80%\n",
      "Run 8/10: Test Accuracy = 97.37%\n",
      "Run 9/10: Test Accuracy = 94.80%\n",
      "Run 10/10: Test Accuracy = 95.87%\n",
      "Result: 95.18 ± 1.34%\n",
      "Running COTEACHING on FashionMNIST0.6...\n",
      "Run 1/10: Test Accuracy = 95.50%\n",
      "Run 2/10: Test Accuracy = 92.43%\n",
      "Run 3/10: Test Accuracy = 95.23%\n",
      "Run 4/10: Test Accuracy = 89.90%\n",
      "Run 5/10: Test Accuracy = 92.63%\n",
      "Run 6/10: Test Accuracy = 94.80%\n",
      "Run 7/10: Test Accuracy = 92.87%\n",
      "Run 8/10: Test Accuracy = 94.33%\n",
      "Run 9/10: Test Accuracy = 94.50%\n",
      "Run 10/10: Test Accuracy = 96.50%\n",
      "Result: 93.87 ± 1.82%\n",
      "Running COTEACHING on CIFAR...\n",
      "Run 1/10: Test Accuracy = 63.30%\n",
      "Run 2/10: Test Accuracy = 63.87%\n",
      "Run 3/10: Test Accuracy = 58.07%\n",
      "Run 4/10: Test Accuracy = 61.03%\n",
      "Run 5/10: Test Accuracy = 63.33%\n",
      "Run 6/10: Test Accuracy = 58.83%\n",
      "Run 7/10: Test Accuracy = 60.43%\n",
      "Run 8/10: Test Accuracy = 60.43%\n",
      "Run 9/10: Test Accuracy = 56.87%\n",
      "Run 10/10: Test Accuracy = 66.30%\n",
      "Result: 61.25 ± 2.78%\n"
     ]
    }
   ],
   "source": [
    "datasets = ['FashionMNIST0.3', 'FashionMNIST0.6', 'CIFAR']\n",
    "methods = ['coteaching'] #add more methods here\n",
    "\n",
    "result = run_all_experiments(datasets, methods, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6574152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                    SCE\n",
      "Dataset                      \n",
      "CIFAR            65.57 ± 3.22\n",
      "FashionMNIST0.3  98.58 ± 0.16\n",
      "FashionMNIST0.6  95.83 ± 0.63\n"
     ]
    }
   ],
   "source": [
    "pivot_df = result.pivot(index='Dataset', columns='Method', values='Result')\n",
    "    \n",
    "print(pivot_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
